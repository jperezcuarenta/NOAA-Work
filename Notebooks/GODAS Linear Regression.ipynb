{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69312d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('my/path/to/module/folder')\n",
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# !pip install netCDF4\n",
    "\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c853858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified code originally provided by Ankur Mahesh from ClimateAi.\n",
    "def load_enso_indices():\n",
    "  \"\"\"\n",
    "  Reads in the txt data file to output a pandas Series of ENSO vals\n",
    "\n",
    "  outputs\n",
    "  -------\n",
    "\n",
    "    pd.Series : monthly ENSO values starting from 1980-01-01\n",
    "  \"\"\"\n",
    "\n",
    "  with open(anomaly_path) as f:\n",
    "    line = f.readline()\n",
    "    enso_vals = []\n",
    "    while line:\n",
    "        yearly_enso_vals = map(float, line.split()[1:]) \n",
    "        enso_vals.extend(yearly_enso_vals)\n",
    "        line = f.readline()\n",
    "\n",
    "  enso_vals = pd.Series(enso_vals)\n",
    "  enso_vals.index = pd.date_range('1980-01-01',freq='MS',\n",
    "                                  periods=len(enso_vals))\n",
    "  enso_vals.index = pd.to_datetime(enso_vals.index)\n",
    "  return enso_vals\n",
    "\n",
    "def assemble_basic_predictors_predictands(start_date, end_date, lead_time,\n",
    "                                    use_pca=False, n_components=32):\n",
    "  \"\"\"\n",
    "  inputs\n",
    "  ------\n",
    "\n",
    "      start_date        str : the start date from which to extract sst\n",
    "      end_date          str : the end date \n",
    "      lead_time         str : the number of months between each sst\n",
    "                              value and the target Nino3.4 Index\n",
    "      use_pca          bool : whether or not to apply principal components\n",
    "                              analysis to the sst field\n",
    "      n_components      int : the number of components to use for PCA\n",
    "\n",
    "  outputs\n",
    "  -------\n",
    "      Returns a tuple of the predictors (np array of sst temperature anomalies) \n",
    "      and the predictands (np array the ENSO index at the specified lead time).\n",
    "\n",
    "  \"\"\"\n",
    "  ds = xr.open_dataset(godas_path)\n",
    "  sst = ds['deepTemp'].sel(time=slice(start_date, end_date)) \n",
    "  num_time_steps = sst.shape[0]\n",
    "\n",
    "  sst = sst.values.reshape(num_time_steps, -1)\n",
    "  sst[np.isnan(sst)] = 0\n",
    "\n",
    "  if use_pca:\n",
    "    pca = sklearn.decomposition.PCA(n_components=n_components)\n",
    "    pca.fit(sst)\n",
    "    X = pca.transform(sst)\n",
    "  else:\n",
    "    X = sst\n",
    "\n",
    "  start_date_plus_lead = pd.to_datetime(start_date) + \\\n",
    "                        pd.DateOffset(months=lead_time)\n",
    "  end_date_plus_lead = pd.to_datetime(end_date) + \\\n",
    "                      pd.DateOffset(months=lead_time)\n",
    "  y = load_enso_indices()[slice(start_date_plus_lead, \n",
    "                                end_date_plus_lead)]\n",
    "\n",
    "\n",
    "  ds.close()\n",
    "  return X, y\n",
    "\n",
    "def plot_nino_time_series(y, predictions, depth, month_lead, title):\n",
    "  \"\"\"\n",
    "  inputs\n",
    "  ------\n",
    "    y           pd.Series : time series of the true Nino index\n",
    "    predictions np.array  : time series of the predicted Nino index (same\n",
    "                            length and time as y)\n",
    "    title                 : the title of the plot\n",
    "    depth                 : depth level being considered\n",
    "    month_lead            : month lead time \n",
    "\n",
    "  outputs\n",
    "  -------\n",
    "    None.  Displays the plot\n",
    "  \"\"\"\n",
    "  images_dir = '/cw3e/mead/projects/cdd101/Figures/NOAA_GODAS_Results'\n",
    "  figName_png = str(depth)+'m_Predictions_'+str(month_lead)+'month.png'\n",
    "  figName_pdf = str(depth)+'m_Predictions_'+str(month_lead)+'month.pdf'\n",
    "\n",
    "  predictions = pd.Series(predictions, index=y.index)\n",
    "  predictions = predictions.sort_index()\n",
    "  y = y.sort_index()\n",
    "\n",
    "  plt.plot(y, label='Ground Truth')\n",
    "  plt.plot(predictions, '--', label='ML Predictions')\n",
    "  plt.legend(loc='best')\n",
    "  plt.title(title)\n",
    "  plt.ylabel(str(depth)+ \" \" + 'm Temperature Anomalies')\n",
    "  plt.xlabel('Date')\n",
    "  plt.savefig(images_dir+\"/\"+figName_png, bbox_inches='tight')\n",
    "  plt.savefig(images_dir+\"/\"+figName_pdf, bbox_inches='tight')\n",
    "  plt.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add04320",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_arr = np.array([105, 155, 205])\n",
    "month_lead_arr = np.array([2, 6, 12])\n",
    "\n",
    "for mm in range(len(month_lead_arr)):\n",
    "  for ii in range(len(depth_arr)):\n",
    "    depth_sel = depth_arr[ii]\n",
    "    month_lead = month_lead_arr[mm]\n",
    "    \n",
    "    depth_string = str(depth_sel)\n",
    "    godas_path = '/cw3e/mead/projects/cdd101/Files/GODAS/godasData_'+depth_string+'m.nc'\n",
    "    anomaly_path = '/cw3e/mead/projects/cdd101/Files/GODAS/fixed_deepTemp_anomalies_'+depth_string+'m.txt'\n",
    "    # Select godas and anomaly path\n",
    "\n",
    "    X_train, y_train = assemble_basic_predictors_predictands('1980-01-01','1995-12-31', lead_time=month_lead)                                                         \n",
    "    X_val, y_val = assemble_basic_predictors_predictands('1997-01-01','2002-12-31', lead_time=month_lead)\n",
    "\n",
    "    # Linear Regression\n",
    "    regr = sklearn.linear_model.LinearRegression()\n",
    "    regr.fit(X_train,y_train)\n",
    "    predictions = regr.predict(X_val)\n",
    "    corr, _ = scipy.stats.pearsonr(predictions, y_val)\n",
    "    plot_nino_time_series(y_val, predictions, depth_sel, month_lead,\n",
    "        'Predicted and True Ocean Temperature Anomalies at'+' '+str(month_lead)+' '+'Month Lead Time. \\n Corr: {:.2f}'.format(corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33361768",
   "metadata": {},
   "source": [
    "Use GODAS as predictor data with COBE anomalies as predictands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8371ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified code originally provided by Ankur Mahesh from ClimateAi.\n",
    "def load_enso_indices():\n",
    "  \"\"\"\n",
    "  Reads in the txt data file to output a pandas Series of ENSO vals\n",
    "\n",
    "  outputs\n",
    "  -------\n",
    "\n",
    "    pd.Series : monthly ENSO values starting from 1980-01-01\n",
    "  \"\"\"\n",
    "\n",
    "  with open(anomaly_path) as f:\n",
    "    line = f.readline()\n",
    "    enso_vals = []\n",
    "    while line:\n",
    "        yearly_enso_vals = map(float, line.split()[1:]) \n",
    "        enso_vals.extend(yearly_enso_vals)\n",
    "        line = f.readline()\n",
    "\n",
    "  enso_vals = pd.Series(enso_vals)\n",
    "  enso_vals.index = pd.date_range('1980-01-01',freq='MS',\n",
    "                                  periods=len(enso_vals))\n",
    "  enso_vals.index = pd.to_datetime(enso_vals.index)\n",
    "  return enso_vals\n",
    "\n",
    "def assemble_basic_predictors_predictands(start_date, end_date, lead_time,\n",
    "                                    use_pca=False, n_components=32):\n",
    "  \"\"\"\n",
    "  inputs\n",
    "  ------\n",
    "\n",
    "      start_date        str : the start date from which to extract sst\n",
    "      end_date          str : the end date \n",
    "      lead_time         str : the number of months between each sst\n",
    "                              value and the target Nino3.4 Index\n",
    "      use_pca          bool : whether or not to apply principal components\n",
    "                              analysis to the sst field\n",
    "      n_components      int : the number of components to use for PCA\n",
    "\n",
    "  outputs\n",
    "  -------\n",
    "      Returns a tuple of the predictors (np array of sst temperature anomalies) \n",
    "      and the predictands (np array the ENSO index at the specified lead time).\n",
    "\n",
    "  \"\"\"\n",
    "  ds = xr.open_dataset(godas_path)\n",
    "  sst = ds['deepTemp'].sel(time=slice(start_date, end_date)) \n",
    "  num_time_steps = sst.shape[0]\n",
    "\n",
    "  sst = sst.values.reshape(num_time_steps, -1)\n",
    "  sst[np.isnan(sst)] = 0\n",
    "\n",
    "  if use_pca:\n",
    "    pca = sklearn.decomposition.PCA(n_components=n_components)\n",
    "    pca.fit(sst)\n",
    "    X = pca.transform(sst)\n",
    "  else:\n",
    "    X = sst\n",
    "\n",
    "  start_date_plus_lead = pd.to_datetime(start_date) + \\\n",
    "                        pd.DateOffset(months=lead_time)\n",
    "  end_date_plus_lead = pd.to_datetime(end_date) + \\\n",
    "                      pd.DateOffset(months=lead_time)\n",
    "  y = load_enso_indices()[slice(start_date_plus_lead, \n",
    "                                end_date_plus_lead)]\n",
    "\n",
    "\n",
    "  ds.close()\n",
    "  return X, y\n",
    "\n",
    "def plot_nino_time_series(y, predictions, depth, month_lead, title):\n",
    "  \"\"\"\n",
    "  inputs\n",
    "  ------\n",
    "    y           pd.Series : time series of the true Nino index\n",
    "    predictions np.array  : time series of the predicted Nino index (same\n",
    "                            length and time as y)\n",
    "    title                 : the title of the plot\n",
    "    depth                 : depth level being considered\n",
    "    month_lead            : month lead time \n",
    "\n",
    "  outputs\n",
    "  -------\n",
    "    None.  Displays the plot\n",
    "  \"\"\"\n",
    "  images_dir = '/cw3e/mead/projects/cdd101/Figures/NOAA_GODAS_Results/SST_Anomalies'\n",
    "  figName_png = str(depth)+'m_Predictions_'+str(month_lead)+'month.png'\n",
    "  figName_pdf = str(depth)+'m_Predictions_'+str(month_lead)+'month.pdf'\n",
    "\n",
    "  predictions = pd.Series(predictions, index=y.index)\n",
    "  predictions = predictions.sort_index()\n",
    "  y = y.sort_index()\n",
    "\n",
    "  plt.plot(y, label='Ground Truth')\n",
    "  plt.plot(predictions, '--', label='ML Predictions')\n",
    "  plt.legend(loc='best')\n",
    "  plt.title(title)\n",
    "  plt.ylabel('SST Anomalies Using' + \" \" + str(depth) + \"m Depth Data\")\n",
    "  plt.xlabel('Date')\n",
    "  plt.savefig(images_dir+\"/\"+figName_png, bbox_inches='tight')\n",
    "  plt.savefig(images_dir+\"/\"+figName_pdf, bbox_inches='tight')\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c0b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_arr = np.array([105, 155, 205])\n",
    "month_lead_arr = np.array([2, 6, 12])\n",
    "anomaly_path = '/cw3e/mead/projects/cdd101/Files/nino34.long.anom.data.trimmed.txt'\n",
    "    \n",
    "for mm in range(len(month_lead_arr)):\n",
    "  for ii in range(len(depth_arr)):\n",
    "    depth_sel = depth_arr[ii]\n",
    "    month_lead = month_lead_arr[mm]\n",
    "    \n",
    "    depth_string = str(depth_sel)\n",
    "    godas_path = '/cw3e/mead/projects/cdd101/Files/GODAS/godasData_'+depth_string+'m.nc'\n",
    "\n",
    "    X_train, y_train = assemble_basic_predictors_predictands('1980-01-01','1995-12-31', lead_time=month_lead)                                                         \n",
    "    X_val, y_val = assemble_basic_predictors_predictands('1997-01-01','2002-12-31', lead_time=month_lead)\n",
    "\n",
    "    # Linear Regression\n",
    "    regr = sklearn.linear_model.LinearRegression()\n",
    "    regr.fit(X_train,y_train)\n",
    "    predictions = regr.predict(X_val)\n",
    "    corr, _ = scipy.stats.pearsonr(predictions, y_val)\n",
    "    plot_nino_time_series(y_val, predictions, depth_sel, month_lead,\n",
    "        'Predicted and True Ocean Temperature Anomalies at'+' '+str(month_lead)+' '+'Month Lead Time. \\n Corr: {:.2f}'.format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846a627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
